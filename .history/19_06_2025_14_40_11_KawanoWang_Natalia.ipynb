{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8101b05c-0711-4272-a81e-0b41919d4eb2",
   "metadata": {},
   "source": [
    "# Title: Accuracy of Predicting Newsletter Subscription by Looking at Player's Age and Hours Played "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae48adf-a6a3-4dfd-bc5b-cbfc73b568e5",
   "metadata": {},
   "source": [
    "Link to git hub repository: https://github.com/25494998/NataliaProject.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d7f03-c608-4153-b775-623cd477cd55",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c217f-1624-4fab-a36b-221cc4d9b865",
   "metadata": {},
   "source": [
    "\n",
    "##### Understanding user engagement in online platforms such as video games is critical for developers and researchers. In this project, I analyzed data from a Minecraft research server to determine if using players' **age** and **hours played** can be a reliable way to predict whether they subscribe to a game-related newsletter.The aim of this project is to help a research group at UBC target their recruitment efforts \n",
    "\n",
    "#### Question:  \n",
    "##### How accurately can hours played and age of a player predict if they are going to subscribe to the newsletter or not? #####\n",
    "\n",
    "\n",
    "#### Datase:  \n",
    "##### For this project I used the data _players.csv_, which contains the following variables: \n",
    "| Variable       | Description                                      | Type        |\n",
    "|----------------|--------------------------------------------------|-------------|\n",
    "| experience     | Experience metric (not used in this analysis)    | Numeric     |\n",
    "| subscribe      | Whether the player subscribed to the newsletter  | Logical |\n",
    "| hashedEmail    | Unique identifier for player (not used)          | Text        |\n",
    "| played_hours   | Total hours the player played                    | Numeric     |\n",
    "| name           | Player name (not used)                           | Text        |\n",
    "| gender         | Player gender (not used)                         | Text        |\n",
    "| Age            | Player age                                       | Numeric     |\n",
    "\n",
    "\n",
    "##### This dataset contains 196 observations. #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb762585-3e75-4a78-b9da-4e6d8559b7a4",
   "metadata": {},
   "source": [
    "## Methods And Results ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb595098-6e7d-4506-88d1-c918a9e1c8fc",
   "metadata": {},
   "source": [
    "### Exploring the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced8a98-5941-475c-96b9-6bede9724d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Libraries\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c52fd4-8dd5-4304-a99e-45a317e0c162",
   "metadata": {},
   "source": [
    "1. The first thing I will do is to explore the data so we can prepare it for our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb54851-39ac-4ab1-ac9d-b4c2ad973e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the Data \n",
    "players<- read_csv(\"players.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3415ce53-74ec-4d62-a752-29f76eb4d9d6",
   "metadata": {},
   "source": [
    "We can see that this data set has 196 rows and 7 variables. This data set is also organized using the \",\" delimeter, which is why I have used the `read_csv` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff508b19-f7f3-48b7-ab44-45b4496d153e",
   "metadata": {},
   "source": [
    "2. After exploring the dataset, I identified the key variables relevant to my analysis: Age, played_hours, and subscribe. Since the goal is to evaluate how accurately Age and Hours Played can predict newsletter subscription, I will shorten the dataset to just these three variables.\n",
    "\n",
    "To prepare the data for modeling, I will:\n",
    "\n",
    "- Use `drop_na()` to remove rows with missing values\n",
    "  \n",
    "- Use `select()` to keep only the relevant columns/variables: Age, played_hours, and subscribe\n",
    "\n",
    "- Use `mutate()` to convert the subscribe variable from a logical to a factor type, since I am working with a classification model\n",
    "\n",
    "I have also added the `slice` function, because I don't want to vizualize the whole data, since I already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7303229-5abd-4650-a051-c9746513042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and clean the data\n",
    "players<- read_csv(\"players.csv\") |> \n",
    "drop_na()|>\n",
    "select(subscribe, played_hours, Age)|> \n",
    "mutate(subscribe= as.factor(subscribe))  \n",
    "\n",
    "slice(players, 0:20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38b5a2-87c0-43e7-be0c-ade5b19eafd9",
   "metadata": {},
   "source": [
    "3. Now that I have loaded, explored, and cleaned the dataset, I want to gain a better understanding of the overall characteristics of the player population. Specifically, I am interested in identifying metrics related to age and hours played. To do this, I use the `summarize()` function to calculate two key summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679039e-9c9d-452c-aec7-4df580e55fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_summary <- players |>\n",
    "summarize(mean_age = mean(Age, na.rm = TRUE),\n",
    "mean_hours = mean(played_hours, na.rm = TRUE))\n",
    "players_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98035dd-4520-4ae0-b1fa-4b28b524595d",
   "metadata": {},
   "source": [
    "This code computes the average age (mean_age) and average number of hours played (mean_hours) across all players. The `na.rm = TRUE` argument ensures that any missing values are excluded from the calculations, which helps avoid getting NA results. These metrics provide a baseline understanding of the dataset values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e233e-e920-4859-b1ca-4c252ab05058",
   "metadata": {},
   "source": [
    "4. To assess how important standardization is before modeling, I will calculate the range of values for both played_hours and Age. This helps identify differences in scale, which can significantly affect the distance-based model of KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3054668-156e-480c-8d98-0650d7bdc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "played_hours_range <- players |>\n",
    "summarise(hours_range = max(played_hours, na.rm = TRUE) - min(played_hours, na.rm = TRUE))\n",
    "\n",
    "Age_range <- players |>\n",
    "summarise(age_range = max(Age, na.rm = TRUE) - min(Age, na.rm = TRUE))\n",
    "\n",
    "Age_range\n",
    "played_hours_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712b2e5b-04eb-400d-8253-c9316db90dd8",
   "metadata": {},
   "source": [
    "We can observe that _played_hours_ has a significantly larger range of values compared to _Age_. This difference in scale means that, without standardization, the played_hours variable would disproportionately influence the classifier’s decisions. To ensure both predictors contribute equally to the model, I will need to standardize the variables before training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48646b76-56ad-4678-985f-6baff4818360",
   "metadata": {},
   "source": [
    "### Scatter Plot Visualization ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef5459-315b-47d1-9be1-778187371334",
   "metadata": {},
   "source": [
    "To explore the relationship between the predictors and the class predicted, I created a scatter plot of Age vs. Played Hours, with points colored based on subscription status.\n",
    "\n",
    "A scatter plot is an appropriate choice here because:\n",
    "\n",
    "- It allows us to visualize the relationship between two continuous variables — in this case, Age and Hours Played.\n",
    "\n",
    "- By adding color to indicate whether or not a player subscribed, we can visually examine the target variable (subscription) relation (if any) to the two predictors.\n",
    "\n",
    "- This helps identify clusters, trends, or patterns in the data — for example, whether subscribers tend to have higher playtime or fall within a specific age group.\n",
    "\n",
    "It also gives a sense of overlap between classes, which is important when evaluating how well these variables might separate subscribed from non-subscribed players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c21a9-eeb5-488f-8304-77379747782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "players |> \n",
    "ggplot(aes(x = Age, y = played_hours, color = subscribe)) +\n",
    "geom_point(alpha = 0.4) +\n",
    "labs(title = \"Scatter Plot of Age vs Played Hours by Subscription Factor\",\n",
    "x = \"Age\",\n",
    "y = \"Played Hours\",\n",
    "color = \"Subscribed\") +\n",
    "ylim(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc7714-9b81-4ed5-91da-194ee0dc0b4f",
   "metadata": {},
   "source": [
    "**Figure 1**\n",
    "Scatter plot that shows each observation in the data set and is colored by wheter they player has subscribed or not. Age being in the x-axis and plyed hours in the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57186b-d8db-4bef-b83a-4dfca68d6134",
   "metadata": {},
   "source": [
    "From the scatter plot, I observed that the data is fairly spread out in terms of Age, while Played Hours is more concentrated. In particular, most players have fewer than 7.5 hours of gameplay. To better visualize this dense region, I limited the y-axis (representing hours played) to range from 0 to 10, instead of 0 to 200. This adjustment helps focus on where the majority of the data points lie and makes patterns in the lower-hour range easier to interpret, especially since many points were clustered below 5 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd890de-209d-4e4c-93cb-4c5e5d4ee561",
   "metadata": {},
   "source": [
    "### *Step 1*: Data Splitting\n",
    "For us to find the best number of K as well as test if our classifier is a good model we will split the data into a training and test subset. I chose to pick a proportion of 70%, because that is the proportion I have seen in most of the tutorials and worksheets.\n",
    "\n",
    "Data splitting is important in the case of this model for us to evaluate our classifier. \n",
    "\n",
    "- Train Subset: Train the model so it can learn patterns.\n",
    "\n",
    "- Test Subset: Test the model on unseen data to evaluate how well it generalizes to new data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e923190a-2543-41e4-9136-ff56512893ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "players_split <- initial_split(players, prop = 0.7, strata = subscribe)\n",
    "players_train <- training(players_split)\n",
    "players_test <- testing(players_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56e6a8-603b-457c-a565-3b51db210d61",
   "metadata": {},
   "source": [
    "### *Step 2*: Preprocessing Recipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17180d77-7468-4a03-aea4-e21fd978d469",
   "metadata": {},
   "source": [
    "To ensure the classifier treats all predictors proportionally, I created a recipe that standardizes the features. This process puts played_hours and Age on the same scale, preventing any variable with a larger numeric range, in this case the _played_hours_ variable, from dominating the classifier. `step_center` makes the variable have a mean zero and `step_scale` divides the variable by SE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9068448-07ca-47a7-b763-e921c97cdd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_recipe <- recipe(subscribe ~ played_hours + Age, data = players_train) |>\n",
    "step_center(all_predictors()) |>\n",
    "step_scale(all_predictors())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4240b9-f2c5-4636-8c2f-30ee71dbd32b",
   "metadata": {},
   "source": [
    "### *Step 3*: Specify KNN Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ff5e1-fa3b-4a4c-b518-5ceabb1a2b21",
   "metadata": {},
   "source": [
    "In this step, I define the K-Nearest Neighbors (KNN) model specification. I set the number of neighbors to tune(), because this allows me to experiment with different values of k and select the one that provides the best classification model.\n",
    "\n",
    "The model uses the \"kknn\" engine and is set to operate in classification mode, as my goal is to predict a categorical outcome ( if the player is subscribed or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e8bc65-f3ff-4355-82d3-caf5e382570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "set_engine(\"kknn\") |>\n",
    "set_mode(\"classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f42dab-a4ad-43ef-b819-0749ff453f03",
   "metadata": {},
   "source": [
    "### *Step 4*: 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753928d4-5dad-4d5a-9c33-a022d5736074",
   "metadata": {},
   "source": [
    "I chose to perform 5-fold cross-validation to ensure that every data point is used at least once for validation and at least once for training. This approach helps provide a more reliable estimate of the model’s performance by reducing the impact of random chance of a particular data split.\n",
    "\n",
    "By repeatedly training and validating the model across different subsets of the data, 5-fold cross-validation also helps prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49cbd2-175a-44fb-a0ca-829e29b9e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "players_vfold <- vfold_cv(players_train, v = 5, strata = subscribe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245eebbc-73c7-427f-a7a7-dcba7d3062f0",
   "metadata": {},
   "source": [
    "### *Step 5*: Create Grid of K values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc896321-fd53-4f25-a0e7-57c52a5eabd2",
   "metadata": {},
   "source": [
    "I have chosen to test a number of neigbors from 1 to 20, since I have tested different ranges, but the best k seems to fall inside this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39aeeb-9e54-4944-9e81-f909c29f4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals <- tibble(neighbors = seq(1, 20, by = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5583f-70a6-4ab2-a67d-52c40992ce86",
   "metadata": {},
   "source": [
    "### *Step 6: Define Workflow and Tune Model*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579e9e4-cb4a-4667-bcf9-14baabc20a64",
   "metadata": {},
   "source": [
    "In this step, I create a workflow that combines the preprocessing recipe and the KNN model specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7599094-1f37-45a3-b8f6-b110e2cda5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_workflow <- workflow() |>\n",
    "add_recipe(players_recipe) |>\n",
    "add_model(knn_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d593f3-1c61-4e6c-a0e4-f3c3380d3432",
   "metadata": {},
   "source": [
    "Next, I use this workflow to find the number of neighbors (k) using the grid of values defined in k_vals. And, again, the tuning is done with 5-fold cross-validation.\n",
    "\n",
    "To ensure reproducibility, I set a random seed before tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e60c1-5c1e-4d82-8a75-2f56eb640392",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "knn_results <- players_workflow |>\n",
    "tune_grid(resamples = players_vfold, grid = k_vals) |>\n",
    "collect_metrics()\n",
    "\n",
    "knn_results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a77b97-b9fe-48e9-8eed-096533d48179",
   "metadata": {},
   "source": [
    "The knn_results table summarizes how the K-Nearest Neighbors (KNN) classifier performed across different numbers of neighbors (k). For each k, it reports:\n",
    "\n",
    "- neighbors: The number of neighbors (k) used in the KNN model\n",
    "\n",
    "- .metric: The performance metric being reported (in this case either accuracy or ROC AUC)\n",
    "\n",
    "- .estimator: the class we are trying to predict is a binary variable, which is why in teh entire knn_results ouput we have \"binary\" in the .estimator column\n",
    "\n",
    "- mean: The average value of accuracy across the cross-validation folds\n",
    "\n",
    "- n: The number of resamples used in cross-validation, in the case of my analysis, 5\n",
    "\n",
    "- std_err: The standard error of the metric’s mean\n",
    "\n",
    "- .config: #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c4ffa2-b9d3-461a-9f66-8f5dcaf7526a",
   "metadata": {},
   "source": [
    "### *Step 7: Select Best K by Accuracy*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b5a8df-f68d-4a8a-9b07-0200e3425475",
   "metadata": {},
   "source": [
    "Having identified k = 13 as the optimal number of neighbors, I will use this value to define the final model specification. The following code filters the tuning results to show only the accuracy metrics for each value of neighbors (k). By isolating accuracy, I can focus on how well the model accurately classifies players at different k values, which helps us answer the question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eebd3b6-229d-4d7a-a921-e67e4efa5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies <- knn_results |> filter(.metric == \"accuracy\")\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88dde30-b72d-493b-81af-eb786729dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k <- accuracies |> \n",
    "slice_max(mean) |> \n",
    "pull(neighbors)\n",
    "\n",
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db499b-75c4-4873-8170-ff96ce862d11",
   "metadata": {},
   "source": [
    "In this step I was able to find that the best number of neighbours would be 13. The output of _accuracies_ has the same variables from the output of knn results. The only difference is that I have now filtered to only see where `.metric=\"accuracy\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21548587-e387-481f-9023-adcc5eefa8e2",
   "metadata": {},
   "source": [
    "### Step 8: Finalize Model with Best K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8562fe-605c-410a-ac5b-6d5d4beb60ff",
   "metadata": {},
   "source": [
    "After identifying the optimal number of neighbors (best_k), I finalized the KNN model specification using this value. I then created a workflow that combines the preprocessing steps with the finalized model. Finally, I trained the complete model on the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b360cb-4c58-47b8-9cd8-7769dee7f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = best_k) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "final_workflow <- workflow() |>\n",
    "  add_recipe(players_recipe) |>\n",
    "  add_model(final_knn_spec)\n",
    "\n",
    "final_fit <- final_workflow |> fit(data = players_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8403c4-c8e6-4d73-bb4b-5249c18e1f04",
   "metadata": {},
   "source": [
    "### *Step 9*: Predict on Test Set & Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f1f08-d9d9-4b01-b6dd-28dd1dc31899",
   "metadata": {},
   "source": [
    "After training the final model, I used it to generate predictions on the test dataset. The predicted subscription variable were combined with the actual test data for comparison by using the `bind_cols` funtion. Then, I calculated performance metrics by comparing the predicted classes against the true subscription labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ca240-83ee-4bb1-acec-c09970e078fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions <- predict(final_fit, players_test) |> \n",
    "bind_cols(players_test)\n",
    "\n",
    "test_metrics <- test_predictions |> \n",
    "metrics(truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3069ff7d-db1e-4f9f-840e-acbddf0ca65f",
   "metadata": {},
   "source": [
    "I woud also like to highlight that accuracy is the total number of correct predictions over the total number of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069ea24-bf03-4ded-bdea-017bec69f73b",
   "metadata": {},
   "source": [
    "### *Step 10: Confusion Matrix*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d54e7-4610-4ae5-964f-2b4a6e628860",
   "metadata": {},
   "source": [
    "I created a confusion matrix to better vizualize the performance of the classifier. A confusion matrix is a table that compares the predicted classes against the actual classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fef59-bd7e-4622-bbd6-d71dcdb0a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_data <- conf_mat(test_predictions, truth = subscribe, estimate = .pred_class)\n",
    "conf_matrix_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265819a9-4103-409d-a724-be7e7e97a961",
   "metadata": {},
   "source": [
    "The following code formats the above confusion matrix as a data frame so I can later plor a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248bc2f-86f9-4df0-bb41-818a0832c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_data <- data.frame(\n",
    "Prediction = c(\"FALSE\", \"FALSE\", \"TRUE\", \"TRUE\"),\n",
    "Truth = c(\"FALSE\", \"TRUE\", \"FALSE\", \"TRUE\"),\n",
    "Count = c(3, 3, 13, 40))\n",
    "conf_matrix_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194875f-beeb-45b4-a460-44988b836888",
   "metadata": {},
   "source": [
    "I chose to visualize the confusion matrix as a stacked bar chart showing proportions to better understand the relative distribution of predictions within each actual class. This plot highlights the percentage of correct and incorrect predictions for subscribers and non-subscribers separately. By focusing on proportions, it becomes easier to compare how well the model performs across classes regardless of class size differences, providing a clearer picture of classification accuracy and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52d7bb-b875-4f9a-80ee-8a0b19358a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(conf_matrix_data, aes(x = Truth, y = Count, fill = Prediction)) +\n",
    "geom_bar(stat = \"identity\", position = \"fill\") +  \n",
    "labs(title = \"Confusion Matrix (In Proportions)\", x = \"Actual (Truth)\",y = \"Proportion\", fill = \"Predicted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5dbb07-84a2-4214-a10d-78b58647f063",
   "metadata": {},
   "source": [
    "**Figure 2**\n",
    "Bar Chart of the proportions of how many correct and wrong predictions the classifier got it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364effc3-a843-4a77-9de5-fccae1459674",
   "metadata": {},
   "source": [
    "It is noticeable to see that the classifier predicted most of it as true. So let's explore if the orginal data set has a bigger percante of subscribed players. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56104284-8834-41d0-8528-d5c7940a2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "total <- nrow(players)\n",
    "players_percentage <- players |>\n",
    "summarize(\n",
    "subscribers = sum(subscribe == TRUE, na.rm = TRUE),\n",
    "percent_subscribed = (subscribers / total) * 100)\n",
    "\n",
    "players_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4b237-a322-43bb-91ae-f2c9449260e5",
   "metadata": {},
   "source": [
    "We can see from this output that indeed the majority of players are subscribed, which could justify why our classifier predicted a lot more of subscribers rather than non-subscribers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0fc24f-a573-42ee-8bd8-2e18030b7566",
   "metadata": {},
   "source": [
    "### Notes on the Method Chosen to Perform this Data Analysis ###\n",
    "For this project I used a classification model because the goal is to predict whether a player subscribes based on 2 variables: age and played hours, which are both numerical. This method is appropriate since I am trying to predict a factor/category. I split the data into training and test sets (70/10) and used 5-fold cross-validation on the training set to tune and compare models. \n",
    "\n",
    "The main assumption that I have used when implementing the KNN classifier is that similar observations have similar caratheristics. However, one limitation of this model is that it can be affected by noise and randomness (even tough I used cross validation to avoid it). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da90c992-881c-4048-86f2-5eb6f081aee4",
   "metadata": {},
   "source": [
    "## Discussion and Conclusion ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b2ebda-96ca-4ec0-9465-d614dc7a8cd1",
   "metadata": {},
   "source": [
    "Through this analysis, we found that the classifier I developed achieves an accuracy of approximately 73%, meaning it correctly predicts the subscription status about three-quarters of the time.\n",
    "\n",
    "I was somewhat surprised by this level of accuracy, given that the model relies on only two variables — Age and Played Hours. Intuitively, I expected additional factors to play a significant role in predicting subscription behavior. This result suggests that Age and Played Hours alone hold considerable predictive power, though likely not the full story.\n",
    "\n",
    "However, this finding also indicates that relying solely on these two variables may be insufficient for fully understanding or accurately predicting subscription behavior. Important factors beyond Age and Played Hours may influence subscription decisions, and excluding them could lead to incomplete or misleading conclusions.\n",
    "\n",
    "A key question arising from this analysis is: To what extent could targeted marketing strategies informed by these predictions improve actual subscription conversion rates? Exploring this could help translate predictive insights into practical actions that enhance user engagement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
